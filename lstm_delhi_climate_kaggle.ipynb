{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn   # neural network modules\n",
    "import torch.optim as optim   # optimization algorithms\n",
    "import torch.nn.functional as F   # functions without parameters like activation functions\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset   # dataset management, create batches\n",
    "import torchvision.datasets as datasets   # standard datasets on pytorch\n",
    "import torchvision.transforms as transforms   #transform datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (1462, 5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(\"DailyDelhiClimateTrain.csv\")\n",
    "\n",
    "print(f\"Full train dataset shape is {train_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   meantemp   humidity  wind_speed  meanpressure\n",
       "0  2013-01-01  10.000000  84.500000    0.000000   1015.666667\n",
       "1  2013-01-02   7.400000  92.000000    2.980000   1017.800000\n",
       "2  2013-01-03   7.166667  87.000000    4.633333   1018.666667\n",
       "3  2013-01-04   8.666667  71.333333    1.233333   1017.166667\n",
       "4  2013-01-05   6.000000  86.833333    3.700000   1016.500000"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1462.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.495521</td>\n",
       "      <td>60.771702</td>\n",
       "      <td>6.802209</td>\n",
       "      <td>1011.104548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.348103</td>\n",
       "      <td>16.769652</td>\n",
       "      <td>4.561602</td>\n",
       "      <td>180.231668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.857143</td>\n",
       "      <td>50.375000</td>\n",
       "      <td>3.475000</td>\n",
       "      <td>1001.580357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.714286</td>\n",
       "      <td>62.625000</td>\n",
       "      <td>6.221667</td>\n",
       "      <td>1008.563492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.305804</td>\n",
       "      <td>72.218750</td>\n",
       "      <td>9.238235</td>\n",
       "      <td>1014.944901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.714286</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>42.220000</td>\n",
       "      <td>7679.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meantemp     humidity   wind_speed  meanpressure\n",
       "count  1462.000000  1462.000000  1462.000000   1462.000000\n",
       "mean     25.495521    60.771702     6.802209   1011.104548\n",
       "std       7.348103    16.769652     4.561602    180.231668\n",
       "min       6.000000    13.428571     0.000000     -3.041667\n",
       "25%      18.857143    50.375000     3.475000   1001.580357\n",
       "50%      27.714286    62.625000     6.221667   1008.563492\n",
       "75%      31.305804    72.218750     9.238235   1014.944901\n",
       "max      38.714286   100.000000    42.220000   7679.333333"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(1444, 5)\n"
     ]
    }
   ],
   "source": [
    "# remove outliers\n",
    "\n",
    "# remove using z-score\n",
    "from scipy import stats\n",
    "\n",
    "z_windspeed = np.abs(stats.zscore(train_dataset['wind_speed']))\n",
    "z_meanpressure = np.abs(stats.zscore(train_dataset['meanpressure']))\n",
    "\n",
    "z_data = [z_windspeed,z_meanpressure]\n",
    "z_list = []\n",
    "for x in z_data:\n",
    "    z_list.extend(np.where(x>3)[0].flatten().tolist())\n",
    "\n",
    "print(len(z_list))\n",
    "train_dataset = train_dataset.drop(index = z_list, axis=0)\n",
    "\n",
    "final_dataset = pd.DataFrame(train_dataset)\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   meantemp   humidity  wind_speed  meanpressure\n",
       "0 2013-01-01  10.000000  84.500000    0.000000   1015.666667\n",
       "1 2013-01-02   7.400000  92.000000    2.980000   1017.800000\n",
       "2 2013-01-03   7.166667  87.000000    4.633333   1018.666667\n",
       "3 2013-01-04   8.666667  71.333333    1.233333   1017.166667\n",
       "4 2013-01-05   6.000000  86.833333    3.700000   1016.500000"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset['date'] = pd.to_datetime(final_dataset['date'])\n",
    "\n",
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1444, 4)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set = final_dataset.to_numpy()[:,[1,2,3,4]]\n",
    "out_feature_index = 0 #meantemp\n",
    "feature_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.0, 84.5, 0.0, 1015.6666666666666],\n",
       "       [7.4, 92.0, 2.98, 1017.8],\n",
       "       [7.166666666666667, 87.0, 4.633333333333334, 1018.6666666666666],\n",
       "       ...,\n",
       "       [14.095238095238097, 89.66666666666667, 6.266666666666667,\n",
       "        1017.904761904762],\n",
       "       [15.052631578947368, 87.0, 7.325, 1016.1],\n",
       "       [10.0, 100.0, 0.0, 1016.0]], dtype=object)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1155.2"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1444*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = feature_set[:1155,:]\n",
    "val_df = feature_set[1155:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1444, 4)\n",
      "(1444, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_normalize = ['meantemp', 'humidity', 'wind_speed', 'meanpressure']\n",
    "ycol = ['meantemp']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(feature_set)\n",
    "yscaled_data = scaler.fit_transform(feature_set[:,out_feature_index].reshape(-1,1))\n",
    "# scaler expects 2d --> needs reshape\n",
    "# The -1 in the first dimension indicates that the resulting array should have a size that is automatically determined to ensure that all the elements are included.\n",
    "# The 1 in the second dimension indicates that the resulting array should have a single column.\n",
    "# The purpose of this reshaping is to convert a 1-dimensional array (shape (n,)) into a 2-dimensional array with a single column (shape (n, 1)).\n",
    "\n",
    "print(scaled_data.shape)\n",
    "print(yscaled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "input_size = 4   # num_features\n",
    "sequence_length = 30   #blocksize\n",
    "\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "num_epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 30, 4)\n",
      "(1125, 1)\n",
      "(289, 30, 4)\n",
      "(289, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_data,y_train_data=[],[]\n",
    "x_val_data,y_val_data=[],[]\n",
    "\n",
    "for i in range(sequence_length, len(scaled_data)):\n",
    "    if i < 1155:\n",
    "        x_train_data.append(scaled_data[i - sequence_length : i,  :])\n",
    "        y_train_data.append(yscaled_data[i])\n",
    "        \n",
    "    else:\n",
    "        x_val_data.append(scaled_data[i - sequence_length : i,  :])\n",
    "        y_val_data.append(yscaled_data[i])        \n",
    "    \n",
    "x_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data)\n",
    "x_val_data,y_val_data=np.array(x_val_data),np.array(y_val_data)\n",
    "\n",
    "print(x_train_data.shape)\n",
    "print(y_train_data.shape)\n",
    "print(x_val_data.shape)\n",
    "print(y_val_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.12227074, 0.8209571 , 0.        , 0.53117921],\n",
       "        [0.04279476, 0.90759076, 0.14965474, 0.53414746],\n",
       "        [0.0356623 , 0.84983498, 0.23268466, 0.53535332],\n",
       "        ...,\n",
       "        [0.27001456, 0.49174917, 0.18581293, 0.53419384],\n",
       "        [0.24836245, 0.60148515, 0.16258632, 0.5325126 ],\n",
       "        [0.26637555, 0.65841584, 0.05308941, 0.53422697]],\n",
       "\n",
       "       [[0.04279476, 0.90759076, 0.14965474, 0.53414746],\n",
       "        [0.0356623 , 0.84983498, 0.23268466, 0.53535332],\n",
       "        [0.08151383, 0.66886689, 0.06193764, 0.53326626],\n",
       "        ...,\n",
       "        [0.24836245, 0.60148515, 0.16258632, 0.5325126 ],\n",
       "        [0.26637555, 0.65841584, 0.05308941, 0.53422697],\n",
       "        [0.31179039, 0.60264026, 0.14865035, 0.53498229]],\n",
       "\n",
       "       [[0.0356623 , 0.84983498, 0.23268466, 0.53535332],\n",
       "        [0.08151383, 0.66886689, 0.06193764, 0.53326626],\n",
       "        [0.        , 0.84790979, 0.18581293, 0.53233868],\n",
       "        ...,\n",
       "        [0.26637555, 0.65841584, 0.05308941, 0.53422697],\n",
       "        [0.31179039, 0.60264026, 0.14865035, 0.53498229],\n",
       "        [0.30567686, 0.68811881, 0.11148776, 0.531643  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.35975815, 0.62414318, 0.29359216, 0.52982351],\n",
       "        [0.37088792, 0.59416942, 0.10546139, 0.52709785],\n",
       "        [0.4183952 , 0.47731023, 0.30288763, 0.52503398],\n",
       "        ...,\n",
       "        [0.54148472, 0.58580858, 0.25970765, 0.52657443],\n",
       "        [0.53275109, 0.54042904, 0.33862434, 0.52558059],\n",
       "        [0.55021834, 0.50979785, 0.47080979, 0.52616447]],\n",
       "\n",
       "       [[0.37088792, 0.59416942, 0.10546139, 0.52709785],\n",
       "        [0.4183952 , 0.47731023, 0.30288763, 0.52503398],\n",
       "        [0.40349345, 0.51331133, 0.03749738, 0.52681957],\n",
       "        ...,\n",
       "        [0.53275109, 0.54042904, 0.33862434, 0.52558059],\n",
       "        [0.55021834, 0.50979785, 0.47080979, 0.52616447],\n",
       "        [0.59798035, 0.50835396, 0.40081607, 0.52772976]],\n",
       "\n",
       "       [[0.4183952 , 0.47731023, 0.30288763, 0.52503398],\n",
       "        [0.40349345, 0.51331133, 0.03749738, 0.52681957],\n",
       "        [0.33828239, 0.56259626, 0.29160912, 0.53006611],\n",
       "        ...,\n",
       "        [0.55021834, 0.50979785, 0.47080979, 0.52616447],\n",
       "        [0.59798035, 0.50835396, 0.40081607, 0.52772976],\n",
       "        [0.58282387, 0.62805281, 0.32877171, 0.52681957]]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True)\n",
    "        # batch_first --> If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature)\n",
    "        # bidirectional --> If True, becomes a bidirectional LSTM\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        # need to multiply by 2 because one layer going forward and the other going backward\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # need to define hidden state and cell state to be sent into the LSTM\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        # need to multiply by 2 because one layer going forward and the other going backward\n",
    "        # but they are all concatenated for the same hidden state\n",
    "        # x.size(0) number of examples in a batch size \n",
    "        \n",
    "        out, (hidden_state, cell_state) = self.lstm(x, (h0, c0))   # only output is used here\n",
    "        out = self.fc(out[:, -1, :])   # take the last hidden state and send to the linear layer\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(x_train_data, dtype=torch.float32)\n",
    "train_y = torch.tensor(y_train_data, dtype=torch.float32)\n",
    "val_x = torch.tensor(x_val_data, dtype=torch.float32)\n",
    "val_y = torch.tensor(y_val_data, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of iter(training_loader) so that we can track the batch index and do some intra-epoch reporting\n",
    "    for index, data in enumerate(train_loader):\n",
    "\n",
    "        # Every data instance is an input + label pair\n",
    "        batch_x, batch_y = data\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item() #retrieves the scalar value of the loss function for the current batch\n",
    "        if index % 10 == 9: #reports on loss every 10 batches\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print(f'  batch {index + 1} loss: {last_loss}')\n",
    "            tb_x = epoch_index * len(train_loader) + index + 1  #variable is used to set the x-axis value for the scalar summary in TensorBoard, based on the current epoch and batch index\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "\n",
    "    return last_loss #last calculated batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pirey/miniconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 10 loss: 0.13041657507419585\n",
      "  batch 20 loss: 0.05921053886413574\n",
      "  batch 30 loss: 0.04836498200893402\n",
      "  batch 40 loss: 0.0451042665168643\n",
      "  batch 50 loss: 0.053476500883698465\n",
      "  batch 60 loss: 0.06104078963398933\n",
      "  batch 70 loss: 0.04735032245516777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pirey/miniconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/pirey/miniconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: train 0.04735032245516777 validation 0.05309533327817917\n",
      "EPOCH 2:\n",
      "  batch 10 loss: 0.05338359139859676\n",
      "  batch 20 loss: 0.04525015316903591\n",
      "  batch 30 loss: 0.046081884764134884\n",
      "  batch 40 loss: 0.048356452584266664\n",
      "  batch 50 loss: 0.04856464155018329\n",
      "  batch 60 loss: 0.052419406548142436\n",
      "  batch 70 loss: 0.05966016836464405\n",
      "LOSS: train 0.05966016836464405 validation 0.04732178524136543\n",
      "EPOCH 3:\n",
      "  batch 10 loss: 0.0509306401014328\n",
      "  batch 20 loss: 0.04455137252807617\n",
      "  batch 30 loss: 0.05162761323153973\n",
      "  batch 40 loss: 0.05437312461435795\n",
      "  batch 50 loss: 0.04810599200427532\n",
      "  batch 60 loss: 0.053768891468644144\n",
      "  batch 70 loss: 0.050718089938163756\n",
      "LOSS: train 0.050718089938163756 validation 0.05786284804344177\n",
      "EPOCH 4:\n",
      "  batch 10 loss: 0.04530147537589073\n",
      "  batch 20 loss: 0.05537558607757091\n",
      "  batch 30 loss: 0.04358202163130045\n",
      "  batch 40 loss: 0.05522988401353359\n",
      "  batch 50 loss: 0.04891060777008534\n",
      "  batch 60 loss: 0.052239499613642694\n",
      "  batch 70 loss: 0.046629863977432254\n",
      "LOSS: train 0.046629863977432254 validation 0.05311311036348343\n",
      "EPOCH 5:\n",
      "  batch 10 loss: 0.049259818717837335\n",
      "  batch 20 loss: 0.05227052457630634\n",
      "  batch 30 loss: 0.047756553255021574\n",
      "  batch 40 loss: 0.054864637181162836\n",
      "  batch 50 loss: 0.04607685357332229\n",
      "  batch 60 loss: 0.05205289572477341\n",
      "  batch 70 loss: 0.046186778135597704\n",
      "LOSS: train 0.046186778135597704 validation 0.04855787009000778\n",
      "EPOCH 6:\n",
      "  batch 10 loss: 0.047009444795548916\n",
      "  batch 20 loss: 0.04825288876891136\n",
      "  batch 30 loss: 0.05437332987785339\n",
      "  batch 40 loss: 0.04845079705119133\n",
      "  batch 50 loss: 0.04143452569842339\n",
      "  batch 60 loss: 0.05164468325674534\n",
      "  batch 70 loss: 0.05115221738815308\n",
      "LOSS: train 0.05115221738815308 validation 0.04555670544505119\n",
      "EPOCH 7:\n",
      "  batch 10 loss: 0.049889884516596796\n",
      "  batch 20 loss: 0.04650112129747867\n",
      "  batch 30 loss: 0.050638198480010034\n",
      "  batch 40 loss: 0.05037432536482811\n",
      "  batch 50 loss: 0.04568606447428465\n",
      "  batch 60 loss: 0.055634891614317894\n",
      "  batch 70 loss: 0.04566181041300297\n",
      "LOSS: train 0.04566181041300297 validation 0.05698913708329201\n",
      "EPOCH 8:\n",
      "  batch 10 loss: 0.04537590555846691\n",
      "  batch 20 loss: 0.04154373593628406\n",
      "  batch 30 loss: 0.055797118693590164\n",
      "  batch 40 loss: 0.05319714620709419\n",
      "  batch 50 loss: 0.043113626353442666\n",
      "  batch 60 loss: 0.05533909685909748\n",
      "  batch 70 loss: 0.051504097506403924\n",
      "LOSS: train 0.051504097506403924 validation 0.0538882315158844\n",
      "EPOCH 9:\n",
      "  batch 10 loss: 0.056448517739772795\n",
      "  batch 20 loss: 0.04591928832232952\n",
      "  batch 30 loss: 0.04720038287341595\n",
      "  batch 40 loss: 0.04956082515418529\n",
      "  batch 50 loss: 0.048687794059515\n",
      "  batch 60 loss: 0.051742208749055864\n",
      "  batch 70 loss: 0.04774973019957542\n",
      "LOSS: train 0.04774973019957542 validation 0.045856766402721405\n",
      "EPOCH 10:\n",
      "  batch 10 loss: 0.051219751313328746\n",
      "  batch 20 loss: 0.05047020688652992\n",
      "  batch 30 loss: 0.049233640730381015\n",
      "  batch 40 loss: 0.05371188018471003\n",
      "  batch 50 loss: 0.04970851205289364\n",
      "  batch 60 loss: 0.052828095853328705\n",
      "  batch 70 loss: 0.04743905924260616\n",
      "LOSS: train 0.04743905924260616 validation 0.0429348386824131\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'runs/spaceship_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number + 1}:')\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer) # runs the training function above \n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for index, vdata in enumerate(val_loader):\n",
    "        vbatch_x, vbatch_y = vdata\n",
    "        voutputs = model(vbatch_x)\n",
    "        vloss = criterion(voutputs.squeeze(), vbatch_y)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (index + 1)\n",
    "    print(f'LOSS: train {avg_loss} validation {avg_vloss}')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "    '''\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'model_{timestamp}_{epoch_number}'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    '''\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mse(loader,model): \n",
    "    if loader == train_loader: \n",
    "        print(\"checking mse on training data\")\n",
    "    else:\n",
    "        print(\"checking mse on test data\")\n",
    "    overall_loss = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for x,y in loader:\n",
    "            x= x.to(device=device)\n",
    "            y= y.to(device=device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            unscaled_outputs = scaler.inverse_transform(np.array(outputs))\n",
    "            unscaled_y = scaler.inverse_transform(np.array(y))\n",
    "            \n",
    "            unscaled_outputs = torch.from_numpy(unscaled_outputs)\n",
    "            unscaled_y = torch.from_numpy(unscaled_y)            \n",
    "            \n",
    "            loss = F.mse_loss(unscaled_outputs,unscaled_y,reduction='sum')\n",
    "            \n",
    "            overall_loss += loss.item()\n",
    "            num_samples += x.size(0)\n",
    "\n",
    "        mse = overall_loss / num_samples\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking mse on training data\n",
      "MSE: 45.4095\n",
      "checking mse on test data\n",
      "MSE: 35.9500\n"
     ]
    }
   ],
   "source": [
    "check_mse(train_loader,model)\n",
    "check_mse(val_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
